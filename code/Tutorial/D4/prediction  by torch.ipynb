{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4da22d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network: Net(\n",
      "  (fc1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "fc1.weight Parameter containing:\n",
      "tensor([[ 0.6604, -0.1587],\n",
      "        [ 0.3668,  0.0187]], requires_grad=True)\n",
      "fc1.bias Parameter containing:\n",
      "tensor([-0.2831,  0.3743], requires_grad=True)\n",
      "fc2.weight Parameter containing:\n",
      "tensor([[-0.1073,  0.0520]], requires_grad=True)\n",
      "fc2.bias Parameter containing:\n",
      "tensor([0.0339], requires_grad=True)\n",
      "Total parameters: 9\n",
      "Epoch: 0 Loss : 0.524994\n",
      "Epoch: 1 Loss : 0.914038\n",
      "Epoch: 2 Loss : 0.131237\n",
      "Epoch: 3 Loss : 0.120368\n",
      "Epoch: 4 Loss : 0.861195\n",
      "Epoch: 5 Loss : 0.017679\n",
      "Epoch: 6 Loss : 0.830368\n",
      "Epoch: 7 Loss : 0.815480\n",
      "Epoch: 8 Loss : 0.799882\n",
      "Epoch: 9 Loss : 0.475292\n",
      "Epoch: 10 Loss : 0.427958\n",
      "Epoch: 11 Loss : 0.765592\n",
      "Epoch: 12 Loss : 0.756686\n",
      "Epoch: 13 Loss : 0.746455\n",
      "Epoch: 14 Loss : 0.735188\n",
      "Epoch: 15 Loss : 0.723110\n",
      "Epoch: 16 Loss : 0.035024\n",
      "Epoch: 17 Loss : 0.020607\n",
      "Epoch: 18 Loss : 0.690038\n",
      "Epoch: 19 Loss : 0.679655\n",
      "Epoch: 20 Loss : 0.668511\n",
      "Epoch: 21 Loss : 0.018376\n",
      "Epoch: 22 Loss : 0.645817\n",
      "Epoch: 23 Loss : 0.634288\n",
      "Epoch: 24 Loss : 0.622284\n",
      "Epoch: 25 Loss : 0.609903\n",
      "Epoch: 26 Loss : 0.597233\n",
      "Epoch: 27 Loss : 0.584347\n",
      "Epoch: 28 Loss : 0.072945\n",
      "Epoch: 29 Loss : 0.059661\n",
      "Epoch: 30 Loss : 0.547413\n",
      "Epoch: 31 Loss : 0.000058\n",
      "Epoch: 32 Loss : 0.524917\n",
      "Epoch: 33 Loss : 0.513946\n",
      "Epoch: 34 Loss : 0.010304\n",
      "Epoch: 35 Loss : 0.000230\n",
      "Epoch: 36 Loss : 0.483944\n",
      "Epoch: 37 Loss : 0.474611\n",
      "Epoch: 38 Loss : 0.464917\n",
      "Epoch: 39 Loss : 0.009352\n",
      "Epoch: 40 Loss : 0.446140\n",
      "Epoch: 41 Loss : 0.436990\n",
      "Epoch: 42 Loss : 0.011928\n",
      "Epoch: 43 Loss : 0.038079\n",
      "Epoch: 44 Loss : 0.004604\n",
      "Epoch: 45 Loss : 0.405953\n",
      "Epoch: 46 Loss : 0.399137\n",
      "Epoch: 47 Loss : 0.013033\n",
      "Epoch: 48 Loss : 0.008057\n",
      "Epoch: 49 Loss : 0.012815\n",
      "Epoch: 50 Loss : 0.002224\n",
      "Epoch: 51 Loss : 0.025910\n",
      "Epoch: 52 Loss : 0.025133\n",
      "Epoch: 53 Loss : 0.361197\n",
      "Epoch: 54 Loss : 0.011209\n",
      "Epoch: 55 Loss : 0.004357\n",
      "Epoch: 56 Loss : 0.000377\n",
      "Epoch: 57 Loss : 0.027383\n",
      "Epoch: 58 Loss : 0.033074\n",
      "Epoch: 59 Loss : 0.033461\n",
      "Epoch: 60 Loss : 0.000872\n",
      "Epoch: 61 Loss : 0.333085\n",
      "Epoch: 62 Loss : 0.000160\n",
      "Epoch: 63 Loss : 0.017530\n",
      "Epoch: 64 Loss : 0.325855\n",
      "Epoch: 65 Loss : 0.322932\n",
      "Epoch: 66 Loss : 0.319190\n",
      "Epoch: 67 Loss : 0.314733\n",
      "Epoch: 68 Loss : 0.003663\n",
      "Epoch: 69 Loss : 0.305206\n",
      "Epoch: 70 Loss : 0.001229\n",
      "Epoch: 71 Loss : 0.295690\n",
      "Epoch: 72 Loss : 0.049493\n",
      "Epoch: 73 Loss : 0.285705\n",
      "Epoch: 74 Loss : 0.280274\n",
      "Epoch: 75 Loss : 0.274435\n",
      "Epoch: 76 Loss : 0.019005\n",
      "Epoch: 77 Loss : 0.009118\n",
      "Epoch: 78 Loss : 0.257103\n",
      "Epoch: 79 Loss : 0.032834\n",
      "Epoch: 80 Loss : 0.039506\n",
      "Epoch: 81 Loss : 0.000972\n",
      "Epoch: 82 Loss : 0.037259\n",
      "Epoch: 83 Loss : 0.029682\n",
      "Epoch: 84 Loss : 0.234236\n",
      "Epoch: 85 Loss : 0.010747\n",
      "Epoch: 86 Loss : 0.228666\n",
      "Epoch: 87 Loss : 0.007134\n",
      "Epoch: 88 Loss : 0.222537\n",
      "Epoch: 89 Loss : 0.037651\n",
      "Epoch: 90 Loss : 0.215807\n",
      "Epoch: 91 Loss : 0.005529\n",
      "Epoch: 92 Loss : 0.208676\n",
      "Epoch: 93 Loss : 0.204927\n",
      "Epoch: 94 Loss : 0.007487\n",
      "Epoch: 95 Loss : 0.006855\n",
      "Epoch: 96 Loss : 0.194197\n",
      "Epoch: 97 Loss : 0.036747\n",
      "Epoch: 98 Loss : 0.006444\n",
      "Epoch: 99 Loss : 0.024675\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=2, out_put_dim=1):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=input_dim, out_features=2)\n",
    "        self.fc2 = nn.Linear(in_features=2, out_features=out_put_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        outputs = self.fc2(x)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "# --- 实例化一个网络 --- #\n",
    "my_net = Net()\n",
    "print(\"Network:\", my_net)\n",
    "# parameters\n",
    "for name, params in my_net.named_parameters():\n",
    "    print(name, params)\n",
    "print('Total parameters:', sum(param.numel() for param in my_net.parameters()))\n",
    "# --- optimizer --- #\n",
    "optimizer = optim.Adam(params=my_net.parameters(), lr=0.01)\n",
    "\n",
    "# --- data --- #\n",
    "# Define dataset\n",
    "data = np.array([\n",
    "  [-2, -1],  # Alice\n",
    "  [25, 6],   # Bob\n",
    "  [17, 4],   # Charlie\n",
    "  [-15, -6], # Diana\n",
    "])\n",
    "\n",
    "all_y_trues = np.array([\n",
    "  1, # Alice\n",
    "  0, # Bob\n",
    "  0, # Charlie\n",
    "  1, # Diana\n",
    "])\n",
    "\n",
    "# --- train --- #\n",
    "loss_list = list()\n",
    "for i in range(100):\n",
    "    # --- （1）数据forward --- #\n",
    "    sample_index = np.random.randint(0, 4)\n",
    "    x_train = data[sample_index]\n",
    "    y_label = all_y_trues[sample_index]\n",
    "    # numpy to tensor\n",
    "    x_train = torch.tensor(x_train).to(dtype=torch.float32)\n",
    "    y_label = torch.tensor(y_label).to(dtype=torch.float32).unsqueeze(dim=0)\n",
    "    # --- （2）前向传播 --- #\n",
    "    y_pred = my_net(x_train)\n",
    "    # --- （3）loss反向传播 --- #\n",
    "    loss = F.mse_loss(y_pred, y_label)\n",
    "    # grad zero\n",
    "    optimizer.zero_grad()\n",
    "    # back propagation\n",
    "    loss.backward()\n",
    "    # update weight\n",
    "    optimizer.step()\n",
    "    print('Epoch: %d Loss : %f'%(i, loss.item()))\n",
    "    loss_list.append(loss.item())\n",
    "\n",
    "\n",
    "# # --- test --- #\n",
    "# data_test = np.array([\n",
    "#   [30, 15]  # Tom\n",
    "# ])\n",
    "# x_test = data_test[0]\n",
    "\n",
    "# # numpy to tensor\n",
    "# x_test = torch.tensor(x_test).to(dtype=torch.float32)\n",
    "# y_test_pred = my_net(x_test)\n",
    "# print(y_test_pred.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c9daed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openAI",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
